# WGS-Analysis-Pipeline-on-AWS-with-Nextflow
AWS + Nextflow-based Whole Genome Sequencing (WGS) pipeline project template and practical guide

Project Structure (GitHub-style layout)

nextflow-wgs-pipeline/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ fastq/                  # Sample FASTQ data
â”œâ”€â”€ bin/                       
â”‚   â”œâ”€â”€ bwa_mem.sh              # BWA alignment script
â”‚   â”œâ”€â”€ mark_duplicates.sh      # GATK MarkDuplicates script
â”‚   â”œâ”€â”€ bqsr.sh                 # GATK BaseRecalibration
â”‚   â”œâ”€â”€ variant_calling.sh      # GATK HaplotypeCaller
â”‚   â””â”€â”€ filtering.sh            # Variant filtering
â”œâ”€â”€ envs/
â”‚   â””â”€â”€ gatk.yml                # Conda environment with GATK
â”œâ”€â”€ main.nf                     # Nextflow main pipeline
â”œâ”€â”€ nextflow.config             # Config file (executors, params)
â””â”€â”€ aws.config                  # AWS Batch-specific config block

Key Files Description

1. main.nf (Main Pipeline Definition)
   
params.reads = "./data/fastq/sample_{1,2}.fastq.gz"
params.ref = "./data/ref/genome.fa"

workflow {
    bwa_mem_ch = bwa_mem(params.reads, params.ref)
    dedup_bam_ch = mark_duplicates(bwa_mem_ch)
    recal_bam_ch = bqsr(dedup_bam_ch, params.ref, params.known_sites)
    variants_ch = haplotype_caller(recal_bam_ch, params.ref)
    filtered_vcf_ch = variant_filtering(variants_ch)
}

2. aws.config (AWS Batch Executor Settings)

process.executor = 'awsbatch'

aws {
  region = 'eu-central-1'
  batch {
    cliPath = '/home/ec2-user/miniconda3/bin/aws'
    jobRole = 'arn:aws:iam::123456789012:role/BatchJobRole'
    jobQueue = 'NGSJobQueue'
    jobDefinition = 'NGSJobDefinition'
  }
}

3.Practical Tips Summary

| Item                   | Description                                                                                           |
| ---------------------- | ----------------------------------------------------------------------------------------------------- |
| ðŸ”¹ Use S3              | Store all input/output files in `s3://your-bucket/...` for improved I/O and cost management           |
| ðŸ”¹ Use Spot Instances  | AWS Batch with Spot Instances can save up to 70â€“80% of compute cost                                   |
| ðŸ”¹ Co-locate Resources | Keep `S3`, `Batch`, and compute resources in the same region (e.g., `eu-central-1`)                   |
| ðŸ”¹ Control Parallelism | Use directives like `maxForks`, `cpus`, and `memory` in Nextflow for resource tuning                  |
| ðŸ”¹ Use Docker          | Utilize official Docker images (e.g., `broadinstitute/gatk`, `biocontainers/bwa`) for reproducibility |


4. Downloadable Template

You can download the complete Nextflow project structure as a ZIP file here:
